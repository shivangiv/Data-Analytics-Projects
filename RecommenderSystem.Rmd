---
title: "ALY 6015 PROJECT- BOOK RECOMMENDATION ENGINE"
output:
  html_document:
    df_print: paged
  pdf_document: default
 
---

<style>
body {
text-align: center}
</style>


### ALY 6015 Intermediate Analytics: Final Project Report 




### “Prediction on book ratings”




### Submitted by \n Shivangi Vashi \n Northeastern University, ALY 6015: Intermediate Analytics




### Supervisor \n PhD Vladimir Shapiro




### March, 2020



<style>
body {
text-align: justify}
</style>

## Introduction

As one of the world’s most influential reading sites, Goodreads provides a platform for people interested in talking about books.In this project we will make a prediction of book ratings. For this purpose, first we will need to explore the data and understand what we are working with. Later we will search for any correlation between the variables and see if we can use regression model. Then we will build an algorithm that would help us predict book ratings. The dataset that will be used for this project is called Goodbooks from Kaggle. The information in the data set has been collected since May 25, 2019 and has information about books, their authors, publishers, reviews, number of pages, etc. 

### Variables
average_rating – Target variable<br>
book title- to (recommend) predict given a user <br>
title,authors,language_code,num_pages, ratings_count, text_reviews_count– Predictors for book rating

## Methods


$\large 1. Exploratory~Analysis$ <br> We will look in depth in tha dataset and we will find patterns and if we have any relationship between any of the variables. This will give us better understanding of which variables to be included in the algorithm. 
$\large 2. Recommendation~System$ <br>We attempt to create a recommendation system that will recommend books given a user based on collaborative filtering method. we also use recommender Lab's built in ml algorithms and compare the results of both.


$\Large Part~1:Exploratory~Analysis$ </br>  

I initially used the goodreads data set which only had meta data about books, to see whether those could help me in making the recommending system. However, I quickly found out that these variables will not help me and don't significantly influence ratings of a book and won't help in making the recommendation engine.
At some point, trying to make a model with that dataset did not work. 

I then looked at how netflix does its recommending, and discovered it uses a technique called collaborative filtering (Netflix Recommendation Engine, n.d.).
In this model, a probability model is used that scores the relationship between the user and movie type to predict preferences.
For this reason I downloaded more goodreads data which has user ratings as well. This(Foxtrot, 2018) dataset has over 53.4k user ratings, books, genre and other book related information.


```{r}
library(tidyverse)
library(gridExtra)
library(data.table)
library(methods)
library(Matrix)
library(ggcorrplot)
```


```{r message=FALSE, warning=FALSE}
books10k<-fread("/Users/shivangi/R Projects/goodbooks-10k/books.csv")
ratings10k<-fread("/Users/shivangi/R Projects/goodbooks-10k/ratings.csv")
booktags10k<-fread("/Users/shivangi/R Projects/goodbooks-10k/book_tags.csv")
tags10k<-fread("/Users/shivangi/R Projects/goodbooks-10k/tags.csv")
head(books10k)
head(ratings10k)
head(tags10k)
```



$\large During~the~exploratory~analysis~we~are~going~to~answer~the~following~questions:$

#### What is the distribution of books across languages?

```{r}
lang.table<-table((books10k$language_code)) #categorizing each language and how many observations we have for each of the categories
lang.table2<- sort(lang.table,decreasing = TRUE) #sorting the data from larger to smalled number of observations for each category
lang.table2
lang1<-head(lang.table2,4) # top 4 languages with the highest number of observations. 
lang1
```

```{r}

pie(lang1,
    angle = 90,
    col= c("burlywood1","darksalmon","coral2","brown4"),
    )


```

The most popular languages as a original language of a book are English, US English, UK English. 


####What is the rating distribution for the books?

```{r}

table(books10k$average_rating)%>%
                              barplot(
                                    col = "cadetblue2",
                                    xlab = "average rating",
                                    ylab = "number of books",
                                    main = "Frequencies of different books ratings")


```

From the graph we can see that most of the book have an average rating between 3.70 and 4.06. 

### What is the distribution of the text review counts ?

From the plot we can make the conclussion that 75% of the books have less than 542 reviews, which makes the distributions right skewed. 

```{r}
# text review count
books10k %>% ggplot(aes(x= log1p(work_text_reviews_count)))+ 
  geom_histogram(bins=30)+ ggtitle('Review count Destribution')

# category text review
books10k %>% mutate(
  Categoritaltextreview = case_when(
    work_text_reviews_count < 40 ~ 'low review',
    work_text_reviews_count >= 40 & work_text_reviews_count <=222 ~ 'median review',
    work_text_reviews_count > 222 ~ 'high review',
    TRUE ~ 'unknown'
  )
)

```

2875 book have a high review count which is very close to the mean. That could mean that the variance is small and the review count for each book doen't differ significantly from the review count of the other books. 


####4. Top 20 Authors: 

```{r}

#top 20 books authors
books10k %>%
  group_by(authors) %>%
  summarize(count = length(authors)) %>%
  arrange(desc(count)) %>%
  top_n(10) %>%
  ggplot(aes(x = reorder(authors, count), y = count)) + geom_col(fill = "#5F9F9F",alpha=0.7) +
  labs(x = "Author", y = "Number of Books") +
  ggtitle("Author Distribution")+
  coord_flip()

```

#### Pre processing to clean data.

Data contains duplicates that need to be removed, ie same user has rated the same book multiple times. I also removed records of users that have only rated less than 3 books, since their ratings are insignificant. Their information will not influence the recommendation system.

Since this data set is large, I chose to use only 40% of the user data to create the system.

```{r}
# Removing duplicate ratings
ratings10k[, N := .N, .(user_id, book_id)]
ratings10k <- ratings10k[N == 1]

ratings10k[!duplicated(ratings10k),]
ratings10k<-as.data.table(ratings10k)
ratings10k[, N := .N, .(user_id)]

#remove users who rated less than 3 books
ratings10k <- ratings10k[N > 2]

# selecting 40% of users to create the recc system from
set.seed(1)
sample_size <- 0.4
users <- unique(ratings10k$user_id)
sample_users <- sample(users, round(sample_size * length(users)))
sprintf('Number of ratings (before): %d ', nrow(ratings10k))
ratings10k <- ratings10k[ratings10k$user_id %in% sample_users]
sprintf('Number of ratings (after): %d ', nrow(ratings10k))
```

#### Exploration

Distribution of ratings, mean user ratings, etc were explored. 
Those that rate frequently, do they rate differently from less frequent users ? We can explore this by seeing the next plot.
Results:
The plots showed books are rated 4-5. I saw how users rate, ie number of ratings per user. Then, the ones that rate more, how differently do they rate? I found that frequent users give more lower ratings, could either be they critique more as they read, etc.


```{r message=FALSE, warning=FALSE}

#how are ratings distributed
ratings10k %>% 
  ggplot(aes(x = rating, fill = factor(rating))) +
  geom_bar(color = "grey20")

# No of ratings per user
ratings10k %>% 
  group_by(user_id) %>% 
  summarize(number_of_ratings_per_user = n()) %>% 
  ggplot(aes(number_of_ratings_per_user)) + 
  geom_bar() + coord_cartesian(c(3, 50))

# view how users rate and their frequency
get_cor <- function(df){
    m <- cor(df$x,df$y, use="pairwise.complete.obs");
    eq <- substitute(italic(r) == cor, list(cor = format(m, digits = 2)))
    as.character(as.expression(eq));                 
}

#How do users rate according to their frequency?
tmp <- ratings10k %>% 
  group_by(user_id) %>% 
  summarize(mean_rating = mean(rating), number_of_rated_books = n())

tmp %>% filter(number_of_rated_books <= 100) %>% 
  ggplot(aes(number_of_rated_books, mean_rating)) + stat_bin_hex(bins = 50) + scale_fill_distiller() + stat_smooth(method = "lm", size = 2, se = FALSE) +
  annotate("text", x = 80, y = 1.9, label = get_cor(data.frame(x = tmp$number_of_rated_books, y = tmp$mean_rating)), size = 7, parse = TRUE)

```


#### How are genres distributed?

Since there are user assigned tags and genres, I am choosing those tags that match good-reads built in genres. Since, looking at the tags, some tags do not make sense like some tags are numeric that do not make sense and will not help in recommending.

Therefore I made a list of most common genre tags and then removed some generic genres like fiction, non fiction, ebooks, etc.

I then looked at how genres are distributed.
```{r}
#selecting only goodreads genre tags
genres <- str_to_lower(c("Art", "Biography", "Business", "Chick Lit", "Children's", "Christian", "Classics", "Comics", "Contemporary", "Cookbooks", "Crime", "Ebooks", "Fantasy", "Fiction", "Gay and Lesbian", "Graphic Novels", "Historical Fiction", "History", "Horror", "Humor and Comedy", "Manga", "Memoir", "Music", "Mystery", "Nonfiction", "Paranormal", "Philosophy", "Poetry", "Psychology", "Religion", "Romance", "Science", "Science Fiction", "Self Help", "Suspense", "Spirituality", "Sports", "Thriller", "Travel", "Young Adult"))

exclude_genres <- c("fiction", "nonfiction", "ebooks", "contemporary")
genres <- setdiff(genres, exclude_genres)

available_genres <- genres[str_to_lower(genres) %in% tags10k$tag_name]
available_tags <- tags10k$tag_id[match(available_genres, tags10k$tag_name)]

#Distribution of genres
genredist <- booktags10k %>% 
  filter(tag_id %in% available_tags) %>% 
  group_by(tag_id) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  mutate(sumN = sum(n), percentage = n / sumN) %>%
  arrange(-percentage) %>%
  left_join(tags10k, by = "tag_id")

genredist %>% 
  ggplot(aes(reorder(tag_name, percentage), percentage, fill = percentage)) + geom_bar(stat = "identity") + coord_flip() + scale_fill_distiller() + labs(y = 'Percentage', x = 'Genre')
```
This shows that most books fall under the fantasy, romance and mystery genre.
When a user first joins Netflix and has not rated any shows or movies so far, Netflix just recommends the most popular or trending shows/ movies. A similar thing could be done looking at this genre information.


#### What influences a book's rating?

Correlation plot reveals no strong relations between rating and rating count, text review count etc. Hence other factors might affect it.
```{r}

cormatrix <- books10k %>% 
  select(one_of(c("books_count","original_publication_year","ratings_count", "work_ratings_count", "work_text_reviews_count", "average_rating"))) %>% 
  as.matrix()

ggcorrplot(cor(cormatrix, use = 'pairwise.complete.obs'), type = "lower")

```


$\Large Part~1:Recommendation~Engine$ </br>


#### Collaborative filtering

From the EDA it looks like effects of meta data type variables like ratings count is insignificant, and other quality aspects matter more.

We use the aforementioned user-based collaborative filtering method to make recommendations. It is a popular technique used by Netflix for recommending movies. The way it works is very intuitivw; when thinking of what book to read next, you are most likely going to ask that one friend who has similar taste as you to recommend some to you.
Hence, similarly, we will first find similar users to a chosen current user in terms of their ratings on the same set of books. Then, we will find avg ratings for books rated by those similar users that the current user has not yet read. In theory, the highest avg rated books can be good recommendations to that chosen user.

#### Pre-processing before creating recommendation engine

We need to create a sort of utility matrix on books rated by users so that we know which users have rated which books.
```{r}
dimension_names <- list(user_id = sort(unique(ratings10k$user_id)), book_id = sort(unique(ratings10k$book_id)))

ratingmat <- spread(select(ratings10k, book_id, user_id, rating), book_id, rating) %>% select(-user_id)

ratingmat <- as.matrix(ratingmat)
dimnames(ratingmat) <- dimension_names
ratingmat[1:5, 1:5]
rt<-as.data.frame(ratingmat)


```

#### Find similar users

Lets select a random user id 173. We find users that rated atleast one book rated by this user, lets call the user Bob.
For this user, there are over 700 similar users.
We find similarity with Bob's ratings. We can use Pearson's correlation coefficient. We sort these according to highest similarity. we now have most similar users.


```{r message=FALSE, warning=FALSE}
library(igraph)
chosen_user<-"173"

rated_items <- which(!is.na((as.data.frame(ratingmat[chosen_user, ]))))
selected_users <- names(which(apply(!is.na(ratingmat[ ,rated_items]), 1, sum) >= 2))
head(selected_users,40)


#Normalizing the ratings so as to equalise variance 
rmat<-scale(ratingmat[selected_users, ])

# Finding similarity and sorting acc to highest similarity
similarities <- cor(t(rmat[rownames(rmat)!=chosen_user, ]), rmat[chosen_user, ], use = 'pairwise.complete.obs')
sim <- as.vector(similarities)
names(sim) <- rownames(similarities)
res <- sort(sim, decreasing = TRUE)
head(res, 40)
```


I created a network graph to visualize this similarity with 20 users.
```{r}
#Visualizing similarity
random_users <- selected_users[1:20]
sim_mat <- cor(t(rmat), use = 'pairwise.complete.obs')

g<-graph_from_adjacency_matrix(sim_mat[c(chosen_user, random_users), c(chosen_user, random_users)], mode="undirected", diag=FALSE)
plot(g)


```

### Getting predictions for other books

We take most similar books and avg their ratings for books Bob has not yet rated. We only include those books that have been rated by many other users
```{r}

similar_users <- names(res[1:4])

similar_users_ratings <- data.frame(item = rep(colnames(rmat), length(similar_users)), rating = c(t(as.data.frame(rmat[similar_users,])))) %>% filter(!is.na(rating))

chosen_user_ratings <- data.frame(item = colnames(rmat), rating = rmat[chosen_user,]) %>% filter(!is.na(rating))

predictions <- similar_users_ratings %>% 
  filter(!(item %in% chosen_user_ratings$item)) %>% 
  group_by(item) %>% summarize(mean_rating = mean(rating))


#Recommend best 5 predictions
bookrecs<-predictions %>% 
  arrange(-mean_rating) %>% 
  top_n(5, wt = mean_rating) %>% 
  mutate(book_id = as.numeric(as.character(item))) %>% 
  left_join(select(books10k, authors, title, id), by = c("book_id" = "id")) %>% 
  select(-item) 

bookrecs

```

Hence, given a user, like in this case Bob, we can recommend books he may not have read with a collaborative filter recommendation system that uses preferences of similar users to Bob.

Netlfix does this dynamically by using AI algorithms; similar concepts could be applied to this book recommender and improve the model.

### Using recommender lab

Recommender Lab is a powerful R package solely used for recommendation systems. It has many collaborative filtering based algorithms and uses clustering as well. It also has inbuilt cross validation function to help us test the model.
I will be using recommender lab to generate 5 books and compare the results with the results found using my own collaborative filtering algorithm above.

```{r message=FALSE, warning=FALSE}
library(recommenderlab)
ratingmat0 <- ratingmat
ratingmat0[is.na(ratingmat0)] <- 0
sparse_ratings <- as(ratingmat0, "sparseMatrix")
rm(ratingmat0)
gc()

real_ratings <- new("realRatingMatrix", data = sparse_ratings)
real_ratings

model <- Recommender(real_ratings, method = "UBCF", param = list(method = "pearson", nn = 4))

#Making predictions 
prediction <- predict(model, real_ratings[chosen_user, ], type = "ratings")

as(prediction, 'data.frame') %>% 
  arrange(-rating) %>% .[1:5,] %>% 
  mutate(book_id = as.numeric(as.character(item))) %>% 
  left_join(select(books10k, authors, title, id), by = c("book_id" = "id")) %>% 
  select(-item)

```

As you can see, using clustering algorithm, the results seem more accurate, because the ratings of these books are higher than the ratings  of books found via collaborative filtering.

$\large Conclusion:$  

We have learnt several methods of data analysis implementation in this class. With our simple project, we learnt how to do data exploration, which is a key process before building any sort of model. This project uses descriptive statistics to first analyse the data and distribution of its variables. We then built a recommendation system using two methods- a collaborative filter designed over finding similar users and recommending books they have read, but which the current user has not, and then using recommenderLab's built in UBCF (user based collaborative filtering) algorithm and seeing how both compare.


$\large References:$ </br>  
goodbooks-10k, Foxtrot, 2018. Ten thousand books, one million ratings. Also books marked to read, and tags. Retrieved from kaggle.com:https://www.kaggle.com/zygmunt/goodbooks-10k

Netflix Recommendation Engine. Retrieved from codeacademy.com:https://www.codecademy.com/articles/how-netflix-recommendation-works-data-science

Soumik. (2020, March 9). Goodreads-books. Retrieved from https://www.kaggle.com/jealousleopard/goodreadsbooks/kernels

What Makes a Book Worth Reading? (2018, May 1). Retrieved from http://booksmakeadifference.com/bookgood/

